{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alia's to save vps, early version."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LB: [[-0.1  0. ]] PLB: [[0. 1.]] PUB: [[0.5 5. ]] UB: [[0.6 6. ]] x0_rand: [[0.48351492 3.188929  ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Data handling\n",
    "from scipy.integrate import odeint # numerical integration\n",
    "import numpy as np\n",
    "from pyvbmc import VBMC # VMBC object\n",
    "from pyvbmc import VariationalPosterior\n",
    "from pyvbmc.priors import SplineTrapezoidal\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as scs\n",
    "\n",
    "# Differential equation to be solved\n",
    "def diffyqs(X, t, a,b):\n",
    "    x, vx = X[0], X[1]\n",
    "    dx = vx\n",
    "    dv = -x - np.sign(x) * a * np.abs(x)**b\n",
    "    return [dx, dv]\n",
    "\n",
    "# Initial Condition and time array for solution\n",
    "initial_condition = [0.0, 3.5]\n",
    "t = np.arange(0,10,0.05)\n",
    "\n",
    "# Range of values that parameters can take on\n",
    "a_min = 0.0\n",
    "a_max = 0.5\n",
    "b_min = 1.0\n",
    "b_max = 5.0\n",
    "\n",
    "# gaussian-ish log_likelihood\n",
    "def log_likelihood(theta):\n",
    "    a,b = theta\n",
    "    sol = odeint(diffyqs, initial_condition, t, args=(a,b))\n",
    "    return -np.sum((sol[:,1] - x_true)**2) \n",
    "\n",
    "\n",
    "# Number of parameters (dimension)\n",
    "D = 2\n",
    "\n",
    "# Bounds for VBMC object (LB and UB expanded a bit beyond what the actual true values could be)\n",
    "LB = np.full((1, D), a_min)\n",
    "LB[0][0] = a_min - 0.1\n",
    "LB[0][1] = b_min - 1\n",
    "UB = np.full((1, D), a_max)\n",
    "UB[0][0] = a_max + 0.1\n",
    "UB[0][1] = b_max + 1\n",
    "PLB = np.copy(LB)\n",
    "PLB[0][0] = a_min\n",
    "PLB[0][1] = b_min\n",
    "PUB = np.copy(UB)\n",
    "PUB[0][0] = a_max \n",
    "PUB[0][1] = b_max\n",
    "\n",
    "\n",
    "# pick a random starting point and do initial minimizatio on it\n",
    "np.random.seed(4) # leave this\n",
    "x0_rand = np.random.uniform(PLB, PUB)\n",
    "\n",
    "#set up prior\n",
    "prior = SplineTrapezoidal(LB, PLB, PUB, UB)\n",
    "options = {\n",
    "    \"display\": \"off\"\n",
    "}\n",
    "\n",
    "print(\"LB:\",LB,\"PLB:\",PLB,\"PUB:\",PUB,\"UB:\",UB,'x0_rand:',x0_rand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping x0 to row vector.\n",
      "vbmc:InitialPointsOutsidePB. The starting points X0 are not inside the provided plausible bounds PLB and PUB. Expanding the plausible bounds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/05l43x_n3_961q005lwk1dv40000gp/T/ipykernel_85779/3847861805.py:18: DeprecationWarning: Use of `minimize` with `x0.ndim != 1` is deprecated. Currently, singleton dimensions will be removed from `x0`, but an error will be raised in SciPy 1.11.0.\n",
      "  x0 = minimize(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m vbmc \u001b[39m=\u001b[39m VBMC(log_likelihood, x0, LB, UB, PLB, PUB, prior \u001b[39m=\u001b[39m prior, options \u001b[39m=\u001b[39m options)\n\u001b[1;32m     30\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m1\u001b[39m) \u001b[39m# and this\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m vp, results \u001b[39m=\u001b[39m vbmc\u001b[39m.\u001b[39;49moptimize();\n\u001b[1;32m     32\u001b[0m vbmc\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mvbmc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(vbmc_count) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.pkl\u001b[39m\u001b[39m\"\u001b[39m, overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m vbmc\u001b[39m.\u001b[39mvp\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mvp\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(vbmc_count) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.pkl\u001b[39m\u001b[39m\"\u001b[39m, overwrite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bpe/lib/python3.11/site-packages/pyvbmc/vbmc/vbmc.py:1168\u001b[0m, in \u001b[0;36mVBMC.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     N_slowopts \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1167\u001b[0m \u001b[39m# Run optimization of variational parameters\u001b[39;00m\n\u001b[0;32m-> 1168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvp, var_ss, pruned \u001b[39m=\u001b[39m optimize_vp(\n\u001b[1;32m   1169\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions,\n\u001b[1;32m   1170\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptim_state,\n\u001b[1;32m   1171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvp,\n\u001b[1;32m   1172\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgp,\n\u001b[1;32m   1173\u001b[0m     N_fastopts,\n\u001b[1;32m   1174\u001b[0m     N_slowopts,\n\u001b[1;32m   1175\u001b[0m     Knew,\n\u001b[1;32m   1176\u001b[0m )\n\u001b[1;32m   1178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_state[\u001b[39m\"\u001b[39m\u001b[39mvp_K\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvp\u001b[39m.\u001b[39mK\n\u001b[1;32m   1179\u001b[0m \u001b[39m# Save current entropy\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bpe/lib/python3.11/site-packages/pyvbmc/vbmc/variational_optimization.py:271\u001b[0m, in \u001b[0;36moptimize_vp\u001b[0;34m(options, optim_state, vp, gp, fast_opts_N, slow_opts_N, K)\u001b[0m\n\u001b[1;32m    268\u001b[0m master_decay \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m\n\u001b[1;32m    269\u001b[0m max_iter \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39m10000\u001b[39m, options[\u001b[39m\"\u001b[39m\u001b[39mmax_iter_stochastic\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 271\u001b[0m theta_opt, _, theta_lst, f_val_lst, _ \u001b[39m=\u001b[39m minimize_adam(\n\u001b[1;32m    272\u001b[0m     vb_train_mc_fun,\n\u001b[1;32m    273\u001b[0m     theta_opt,\n\u001b[1;32m    274\u001b[0m     tol_fun\u001b[39m=\u001b[39;49moptions[\u001b[39m\"\u001b[39;49m\u001b[39mtol_fun_stochastic\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    275\u001b[0m     max_iter\u001b[39m=\u001b[39;49mmax_iter,\n\u001b[1;32m    276\u001b[0m     master_min\u001b[39m=\u001b[39;49mmaster_min,\n\u001b[1;32m    277\u001b[0m     master_max\u001b[39m=\u001b[39;49mmaster_max,\n\u001b[1;32m    278\u001b[0m     master_decay\u001b[39m=\u001b[39;49mmaster_decay,\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    281\u001b[0m \u001b[39mif\u001b[39;00m options[\u001b[39m\"\u001b[39m\u001b[39melcbo_midpoint\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    282\u001b[0m     \u001b[39m# Recompute ELCBO at best midpoint with full variance\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[39m# and more precision.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     idx_mid \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmin(f_val_lst)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bpe/lib/python3.11/site-packages/pyvbmc/vbmc/minimize_adam.py:87\u001b[0m, in \u001b[0;36mminimize_adam\u001b[0;34m(f, x0, lb, ub, tol_fun, max_iter, master_min, master_max, master_decay, use_early_stopping)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, max_iter):\n\u001b[1;32m     85\u001b[0m     is_minibatch_end \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mremainder(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, batch_size) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 87\u001b[0m     y_tab[i], grad \u001b[39m=\u001b[39m f(x)\n\u001b[1;32m     89\u001b[0m     m \u001b[39m=\u001b[39m beta_1 \u001b[39m*\u001b[39m m \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta_1) \u001b[39m*\u001b[39m grad\n\u001b[1;32m     90\u001b[0m     v \u001b[39m=\u001b[39m beta_2 \u001b[39m*\u001b[39m v \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta_2) \u001b[39m*\u001b[39m grad\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bpe/lib/python3.11/site-packages/pyvbmc/vbmc/variational_optimization.py:239\u001b[0m, in \u001b[0;36moptimize_vp.<locals>.vb_train_mc_fun\u001b[0;34m(theta_)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvb_train_mc_fun\u001b[39m(theta_):\n\u001b[0;32m--> 239\u001b[0m     res \u001b[39m=\u001b[39m _neg_elcbo(\n\u001b[1;32m    240\u001b[0m         theta_,\n\u001b[1;32m    241\u001b[0m         gp,\n\u001b[1;32m    242\u001b[0m         vp0,\n\u001b[1;32m    243\u001b[0m         elcbo_beta,\n\u001b[1;32m    244\u001b[0m         ns_ent_K,\n\u001b[1;32m    245\u001b[0m         compute_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    246\u001b[0m         compute_var\u001b[39m=\u001b[39;49mcompute_var,\n\u001b[1;32m    247\u001b[0m         theta_bnd\u001b[39m=\u001b[39;49mtheta_bnd,\n\u001b[1;32m    248\u001b[0m     )\n\u001b[1;32m    249\u001b[0m     \u001b[39mreturn\u001b[39;00m res[\u001b[39m0\u001b[39m], res[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bpe/lib/python3.11/site-packages/pyvbmc/vbmc/variational_optimization.py:1157\u001b[0m, in \u001b[0;36m_neg_elcbo\u001b[0;34m(theta, gp, vp, beta, Ns, compute_grad, compute_var, theta_bnd, _entropy_alpha, separate_K)\u001b[0m\n\u001b[1;32m   1148\u001b[0m             G, _, varG, _, varG_ss \u001b[39m=\u001b[39m _gp_log_joint(\n\u001b[1;32m   1149\u001b[0m                 vp,\n\u001b[1;32m   1150\u001b[0m                 gp,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 compute_var,\n\u001b[1;32m   1155\u001b[0m             )\n\u001b[1;32m   1156\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1157\u001b[0m         G, dG, _, _, _ \u001b[39m=\u001b[39m _gp_log_joint(\n\u001b[1;32m   1158\u001b[0m             vp, gp, grad_flags, avg_flag, jacobian_flag, \u001b[39m0\u001b[39;49m\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[1;32m   1160\u001b[0m         varG \u001b[39m=\u001b[39m varG_ss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1162\u001b[0m \u001b[39m# Entropy term\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bpe/lib/python3.11/site-packages/pyvbmc/vbmc/variational_optimization.py:1380\u001b[0m, in \u001b[0;36m_gp_log_joint\u001b[0;34m(vp, gp, grad_flags, avg_flag, jacobian_flag, compute_var, separate_K)\u001b[0m\n\u001b[1;32m   1378\u001b[0m ell \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(hyp[\u001b[39m0\u001b[39m:D])\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m   1379\u001b[0m ln_sf2 \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m hyp[D]\n\u001b[0;32m-> 1380\u001b[0m sum_lnell \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msum(hyp[\u001b[39m0\u001b[39;49m:D])\n\u001b[1;32m   1382\u001b[0m \u001b[39m# GP mean function hyperparameters\u001b[39;00m\n\u001b[1;32m   1383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(gp\u001b[39m.\u001b[39mmean, gpr\u001b[39m.\u001b[39mmean_functions\u001b[39m.\u001b[39mZeroMean):\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N = 1\n",
    "Na = N # adjust number of grid points in a and b separatley if you want\n",
    "Nb = N\n",
    "\n",
    "vbmc_count = 0 \n",
    "param_list = []\n",
    "\n",
    "for i,a in enumerate(np.linspace(a_min,a_max,Na)):     # a will be y axis in grid\n",
    "    for j,b in enumerate(np.linspace(b_min,b_max,Nb)): # b will be x axis in grid\n",
    "        param_list.append([a,b])\n",
    "\n",
    "        # get truth\n",
    "        sol_true = odeint(diffyqs, initial_condition, t, args=(a,b))\n",
    "        x_true = sol_true[:,1]\n",
    "        \n",
    "        # Do initial optimization to get an x0\n",
    "        np.random.seed(1) # change this\n",
    "        x0 = minimize(\n",
    "            lambda t: -log_likelihood(t),\n",
    "            x0_rand,\n",
    "            bounds=[\n",
    "                (a_min, a_max),\n",
    "                (b_min, b_max),\n",
    "            ],\n",
    "        ).x\n",
    "\n",
    "        # run vbmc and save results\n",
    "        np.random.seed(1) # and this\n",
    "        vbmc = VBMC(log_likelihood, x0, LB, UB, PLB, PUB, prior = prior, options = options)\n",
    "        np.random.seed(1) # and this\n",
    "        vp, results = vbmc.optimize();\n",
    "        vbmc.save(\"vbmc\" + str(vbmc_count) + \".pkl\", overwrite=True)\n",
    "        vbmc.vp.save(\"vp\" + str(vbmc_count) + \".pkl\", overwrite=True)\n",
    "        vbmc_count += 1\n",
    "\n",
    "# save parameter values\n",
    "np.savetxt(\"/Users/gracerojo/Downloads/FullDataSet/param_values.csv\", np.array(param_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading everything back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in saved vps and their associated parameter values\n",
    "param_values = np.loadtxt(\"param_values.csv\")\n",
    "vps = []\n",
    "vbmcs = []\n",
    "for i in range(len(param_values)-1):\n",
    "    vps.append(VariationalPosterior.load(\"vp\" + str(i) + \".pkl\"))\n",
    "    vbmcs.append(VariationalPosterior.load(\"vbmc\" + str(i) + \".pkl\"))\n",
    "\n",
    "\n",
    "#unpack into appropriate 2d thing\n",
    "grid = np.zeros((Na,Nb))\n",
    "vps_2d = grid.tolist()\n",
    "params_2d = grid.tolist()\n",
    "count = 0\n",
    "for i,a in enumerate(np.linspace(a_min,a_max,1)):     # a will be y axis in grid\n",
    "    for j,b in enumerate(np.linspace(b_min,b_max,1)): # b will be x axis in grid\n",
    "        vps_2d[i][j] = vps[count]\n",
    "        params_2d[i][j] = param_values[count]\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
